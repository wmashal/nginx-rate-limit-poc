events {
    worker_connections 1024;
}

env VCAP_SERVICES;

env INSTANCE_INDEX;
env CF_INSTANCE_GUID;

env SEMAPHORE_SIZE;
env SEMAPHORE_THRESHOLD;
env BASE_DELAY_MS;

http {
    include mime.types;
    default_type application/octet-stream;
    lua_shared_dict request_processed 10m;

     lua_shared_dict semaphore 10m;
     lua_shared_dict user_requests 10m;
     lua_shared_dict system_metrics 1m;

    # Improved logging
    log_format detailed_log '$remote_addr - $remote_user [$time_local] '
                          '"$request" $status $body_bytes_sent '
                          '"$http_referer" "$http_user_agent" '
                          'upstream_addr:"$upstream_addr" '
                          'upstream_status:"$upstream_status" '
                          'upstream_response_time:"$upstream_response_time" '
                          'api_version:"$api_version"';

    access_log /var/log/nginx/access.log detailed_log;
    error_log /var/log/nginx/error.log debug;

    # Add DNS resolver for Docker
    resolver 169.254.0.2 valid=10s;  # CF DNS

    # Lua configuration
    lua_package_path "/usr/local/openresty/site/lualib/?.lua;;";

    init_by_lua_block {
        redis = require "resty.redis"
        cjson = require "cjson"
        local active_connections = ngx.shared.user_requests

        function track_connection(key, value)
            return ngx.shared.user_requests:incr(key, value, 60, 0)
        end

        function send_error_json(status, error_type, message)
            ngx.status = status
            ngx.header["Content-Type"] = "application/json"
            ngx.say(cjson.encode({
                error = error_type,
                message = message,
                request_id = ngx.var.x_vcap_request_id
            }))
            return ngx.exit(status)
        end

        -- Helper function for Redis connections
        function get_redis_connection()
            local red = redis:new()
            red:set_timeout(1000)

            local vcap_services = os.getenv("VCAP_SERVICES")
            if not vcap_services then
                return nil, "VCAP_SERVICES not found"
            end

            local ok, vcap = pcall(cjson.decode, vcap_services)
            if not ok then
                return nil, "Failed to parse VCAP_SERVICES"
            end

            local redis_creds = vcap.redis[1].credentials

            local ok, err = red:connect(redis_creds.hostname, tonumber(redis_creds.port))
            if not ok then
                return nil, "Failed to connect: " .. err
            end

            local auth_ok, auth_err = red:auth(redis_creds.password)
            if not auth_ok then
                red:set_keepalive(10000, 100)
                return nil, "Failed to authenticate: " .. auth_err
            end

            return red
        end

        -- Initialize semaphore counter
        local semaphore = ngx.shared.semaphore
        local success, err, forcible = semaphore:set("current_utilization", 0)
        if not success then
            ngx.log(ngx.ERR, "Failed to initialize semaphore: ", err)
        end

        semaphore_size = tonumber(os.getenv("SEMAPHORE_SIZE") or 100)
        semaphore_threshold = tonumber(os.getenv("SEMAPHORE_THRESHOLD") or 50)
        base_delay_ms = tonumber(os.getenv("BASE_DELAY_MS") or 100)

        function calculate_throttling_time(utilization, freq)
            local util_factor = math.pow(utilization / semaphore_size, 2)
            local freq_factor = math.log(freq + 1) / math.log(50)
            local jitter = math.random() * 0.2 - 0.1
            return base_delay_ms * util_factor * freq_factor * (1 + jitter)
        end

        function get_user_priority(freq)
            return math.max(1, 10 - math.floor(freq / 5))
        end

        function get_current_utilization(red)
            local util, err = red:get("current_utilization")
            return tonumber(util) or 0
        end

        function increment_utilization(red)
            local ok, err = red:eval([[
                local current = redis.call('incr', KEYS[1])
                redis.call('expire', KEYS[1], 10)  -- Shorter TTL
                return current
            ]], 1, "current_utilization")
            return tonumber(ok) or 0
        end

        function decrement_utilization(red)
            local ok, err = red:eval([[
                local current = tonumber(redis.call('get', KEYS[1]) or 0)
                if current > 0 then
                    return redis.call('decr', KEYS[1])
                end
                return redis.call('set', KEYS[1], 0)
            ]], 1, "current_utilization")
            return tonumber(ok) or 0
        end

        -- Add cleanup function
        function cleanup_utilization(red)
            return red:eval([[
                local current = tonumber(redis.call('get', KEYS[1]) or 0)
                if current > ARGV[1] then
                    return redis.call('set', KEYS[1], ARGV[1])
                end
                return current
            ]], 1, "current_utilization", tostring(semaphore_size))
        end

        local requests_per_sec = ngx.shared.system_metrics

        function calculate_rps()
            local last_time = tonumber(requests_per_sec:get("last_time")) or 0
            local last_count = tonumber(requests_per_sec:get("last_count")) or 0
            local current_time = tonumber(ngx.now())
            local current_count = tonumber(requests_per_sec:incr("request_count", 1, 0)) or 0

            if current_time - last_time >= 1 then
                local rps = (current_count - last_count) / (current_time - last_time)
                requests_per_sec:set("rps", rps)
                requests_per_sec:set("last_time", current_time)
                requests_per_sec:set("last_count", current_count)
            end
            return tonumber(requests_per_sec:get("rps")) or 0
        end
    }

    init_worker_by_lua_block {
        local delay = 5  -- 5 seconds
        local check = function()
            local red = get_redis_connection()
            if red then
                cleanup_utilization(red)
                red:set_keepalive(10000, 100)
            end
        end
        ngx.timer.every(delay, check)
    }

    # Rate limit configuration per endpoint
    map $request_uri $minute_limit {
        ~*/v[12]/service_bindings     5;
        ~*/v[12]/service_offerings    3;
        ~*/v[12]/service_plans        3;
        ~*/v[12]/service_instances    5;
        default                       10;
    }

    map $request_uri $hour_limit {
        ~*/v[12]/service_bindings     10;
        ~*/v[12]/service_offerings    5;
        ~*/v[12]/service_plans        5;
        ~*/v[12]/service_instances    10;
        default                       20;
    }

    # Version-based routing
    map $uri $api_version {
        ~^/v1/    "v1";
        ~^/v2/    "v2";
        default   "";
    }

    # Upstream definitions
    upstream backend_v1 {
        server sm-mock.cert.cfapps.stagingazure.hanavlab.ondemand.com:443 max_fails=3 fail_timeout=10s;
        keepalive 32;
    }

    upstream backend_v2 {
        server sm-mock-v2.cert.cfapps.stagingazure.hanavlab.ondemand.com:443 max_fails=3 fail_timeout=10s;
        keepalive 32;
    }

    server {
        listen 80;
        server_name localhost;

        # Health check endpoint
        location = /health {
            access_log off;
            add_header Content-Type text/plain;
            return 200 'OK';
        }

        # Redis test endpoint
        location = /redis-test {
            content_by_lua_block {
                local red, err = get_redis_connection()
                if not red then
                    return send_error_json(500, "Redis Error", err)
                end

                local res, err = red:ping()
                if not res then
                    red:set_keepalive(10000, 100)
                    return send_error_json(500, "Redis Error", "Failed to ping Redis: " .. err)
                end

                ngx.say("Redis connection successful! PING response: ", res)

                local keys, err = red:keys("*")
                if not keys then
                    red:set_keepalive(10000, 100)
                    return send_error_json(500, "Redis Error", "Failed to retrieve keys: " .. tostring(err))
                end

                ngx.say("Total number of keys: " .. #keys)
                ngx.say("\nKey Details:")
                for _, key in ipairs(keys) do
                    local key_type = red:type(key)
                    if key_type then
                        ngx.say(string.format("Key: %s, Type: %s", key, key_type))
                    end
                end

                red:set_keepalive(10000, 100)
            }
        }

        access_by_lua_block {
            track_connection("active_conn", 1)
        }

        log_by_lua_block {
            track_connection("active_conn", -1)
        }

        location = /metrics {
            content_by_lua_block {
                local red = get_redis_connection()
                local ordered_metrics = {
                    semaphore_size = semaphore_size,
                    semaphore_threshold = semaphore_threshold,
                    current_utilization = 0,
                    throttle_stats = {
                        throttle_percentage = 0,
                        is_throttling = false,
                        requests_per_second = calculate_rps(),
                        delay_info = {
                            base_delay_ms = 0,
                            client_frequency = 0,
                            client_priority = 0,
                            final_delay_ms = 0
                        }
                    }
                }

                if red then
                    local utilization = get_current_utilization(red)
                    local user_freq = ngx.shared.user_requests:get(ngx.var.remote_addr) or 1
                    local delay = calculate_throttling_time(utilization, user_freq)

                    ordered_metrics.current_utilization = utilization
                    ordered_metrics.throttle_stats.is_throttling = utilization >= (semaphore_size * semaphore_threshold / 100)
                    ordered_metrics.throttle_stats.throttle_percentage = (utilization / semaphore_size) * 100
                    ordered_metrics.throttle_stats.delay_info = {
                        base_delay_ms = math.floor(delay),
                        client_frequency = user_freq,
                        client_priority = get_user_priority(user_freq),
                        final_delay_ms = math.floor(delay * (1 - get_user_priority(user_freq)/10))
                    }
                    red:set_keepalive(10000, 100)
                end

                ngx.header["Content-Type"] = "application/json"
                ngx.say(require("cjson").encode(ordered_metrics))
            }
        }

        # Handle both v1 and v2 endpoints
        location ~ ^/v[12]/.+ {
            # At the beginning of the location block
            proxy_next_upstream error timeout http_502 http_503 http_504;
            proxy_next_upstream_tries 3;
            proxy_connect_timeout 10s;
            proxy_read_timeout 10s;
            proxy_send_timeout 10s;

            # Add error handling
            error_page 502 504 = @handle_error;

            log_by_lua_block {
                local red, err = get_redis_connection()
                if red then
                    decrement_utilization(red)
                    red:set_keepalive(10000, 100)
                end
            }

            content_by_lua_block {

                    -- Do rate limiting first
                    local red, err = get_redis_connection()
                    if not red then
                        return send_error_json(500, "Redis Error", err)
                    end

                    -- Set expiration time for current_utilization key if it doesn't exist
                    red:setnx("current_utilization", 0)
                    red:expire("current_utilization", 60)  -- 60 seconds TTL

                    local current_utilization = increment_utilization(red)
                    local user_ip = ngx.var.remote_addr
                    local user_requests = ngx.shared.user_requests

                    if current_utilization >= (semaphore_size * semaphore_threshold / 100) then
                        local user_freq = user_requests:get(user_ip) or 1
                        local priority = get_user_priority(user_freq)
                        local throttle_time = calculate_throttling_time(current_utilization, user_freq)
                        throttle_time = throttle_time * (1 - priority/10)
                        ngx.sleep(throttle_time / 1000)
                    end

                    user_requests:incr(user_ip, 1, 60, 1)

                    local endpoint = ngx.var.uri:match("/[^/]+/([^/]+)")
                    if not endpoint then
                        red:set_keepalive(10000, 100)
                        return send_error_json(400, "Bad Request", "Could not determine endpoint")
                    end

                    local time_window = 30
                    local version = ngx.var.api_version
                    local minute_key = math.floor(ngx.now() / time_window)
                    local rate_key = version .. ":" .. endpoint
                    local minute_limit = tonumber(ngx.var.minute_limit)
                    local hour_limit = tonumber(ngx.var.hour_limit)

                    -- Rate limit checks
                    local minute_count, err = red:incr(rate_key .. ":30s:" .. minute_key)
                    if not minute_count then
                        red:set_keepalive(10000, 100)
                        return send_error_json(500, "Redis Error", "Failed to increment counter")
                    end

                    red:expire(rate_key .. ":30s:" .. minute_key, time_window)

                    -- Set common headers
                    ngx.header["X-API-Version"] = version
                    ngx.header["X-RateLimit-30s-Limit"] = minute_limit
                    ngx.header["X-RateLimit-30s-Remaining"] = math.max(0, minute_limit - minute_count)
                    ngx.header["X-RateLimit-30s-Reset"] = time_window - (ngx.now() % time_window)

                    if minute_count > minute_limit then
                        red:set_keepalive(10000, 100)
                        return send_error_json(429, "Rate Limit Exceeded",
                            string.format("Rate limit exceeded for %s API (30s window). Current count: %d, Limit: %d",
                                version, minute_count, minute_limit))
                    end

                    -- Increment 2m counter (after the 30s check)
                    local hour_window = 120  -- 2 minutes in seconds
                    local hour_bucket = math.floor(ngx.now() / hour_window)
                    local hour_count, err = red:incr(rate_key .. ":2m:" .. hour_bucket)
                    if not hour_count then
                        red:set_keepalive(10000, 100)
                        return send_error_json(500, "Redis Error", "Failed to increment counter")
                    end

                    red:expire(rate_key .. ":2m:" .. hour_bucket, hour_window * 2)  -- double the window for expiry

                    -- Set 2m headers
                    ngx.header["X-RateLimit-2m-Limit"] = hour_limit
                    ngx.header["X-RateLimit-2m-Remaining"] = math.max(0, hour_limit - hour_count)
                    ngx.header["X-RateLimit-2m-Reset"] = hour_window - (ngx.now() % hour_window)

                    if hour_count > hour_limit then
                        red:set_keepalive(10000, 100)
                        return send_error_json(429, "Rate Limit Exceeded",
                            string.format("Rate limit exceeded for %s API (2m window). Current count: %d, Limit: %d",
                                version, hour_count, hour_limit))
                    end

                    red:set_keepalive(10000, 100)

                    ngx.header["X-Backend-Host"] = "nginx-instance-" .. (os.getenv("INSTANCE_INDEX") or "unknown")
                    ngx.header["X-Backend-Server"] = os.getenv("CF_INSTANCE_GUID") or "unknown"

                    -- Proxy the request
                    ngx.req.read_body()

                    -- Get the correct backend hostname
                    local backend_host = ngx.var.api_version == "v2"
                        and "sm-mock-v2.cert.cfapps.stagingazure.hanavlab.ondemand.com"
                        or "sm-mock.cert.cfapps.stagingazure.hanavlab.ondemand.com"

                    -- Configure the http client
                    local http = require "resty.http"
                    local httpc = http.new()
                    httpc:set_timeout(10000)

                    -- Force IPv4
                    local res, err = httpc:request_uri("https://" .. backend_host .. ngx.var.uri, {
                        method = ngx.req.get_method(),
                        headers = {
                            ["Host"] = backend_host,
                            ["Connection"] = "keep-alive",
                            ["X-Forwarded-For"] = ngx.var.remote_addr,
                            ["X-Forwarded-Proto"] = "https"
                        },
                        ssl_verify = false,
                        pool = "backend_pool",
                        socket_options = {
                            family = 4  -- Force IPv4
                        }
                    })

                    if not res then
                        ngx.log(ngx.ERR, "Failed to connect to backend: ", err)
                        return send_error_json(502, "Bad Gateway", "Failed to connect to backend: " .. (err or "unknown error"))
                    end

                    -- Copy response headers
                    for k, v in pairs(res.headers) do
                        if k ~= "Transfer-Encoding" and k ~= "Connection" then
                            ngx.header[k] = v
                        end
                    end

                    ngx.status = res.status
                    ngx.say(res.body)
                }
        }
    }
}