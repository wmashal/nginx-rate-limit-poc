events {
    worker_connections 1024;
}

env TOTAL_RATE_LIMIT;
env REDIS_HOST;
env REDIS_PORT;
env SEMAPHORE_SIZE;
env SEMAPHORE_THRESHOLD;
env BASE_DELAY_MS;

http {
    include mime.types;
    default_type application/octet-stream;

    lua_shared_dict semaphore 10m;
    lua_shared_dict user_requests 10m;
    lua_shared_dict system_metrics 1m;

    log_format detailed_log '$remote_addr - $remote_user [$time_local] '
                          '"$request" $status $body_bytes_sent '
                          '"$http_referer" "$http_user_agent" '
                          'upstream_addr:"$upstream_addr" '
                          'upstream_status:"$upstream_status" '
                          'upstream_response_time:"$upstream_response_time" '
                          'api_version:"$api_version"';

    access_log /var/log/nginx/access.log detailed_log;
    error_log /var/log/nginx/error.log debug;

    resolver 127.0.0.11 ipv6=off;
    lua_package_path "/usr/local/openresty/site/lualib/?.lua;;";

    init_by_lua_block {
        redis = require "resty.redis"

        -- Initialize semaphore counter
        local semaphore = ngx.shared.semaphore
        local success, err, forcible = semaphore:set("current_utilization", 0)
        if not success then
            ngx.log(ngx.ERR, "Failed to initialize semaphore: ", err)
        end

        semaphore_size = tonumber(os.getenv("SEMAPHORE_SIZE") or 100)
        semaphore_threshold = tonumber(os.getenv("SEMAPHORE_THRESHOLD") or 50)
        base_delay_ms = tonumber(os.getenv("BASE_DELAY_MS") or 100)

        function calculate_throttling_time(utilization, freq)
            local util_factor = math.pow(utilization / semaphore_size, 2)
            local freq_factor = math.log(freq + 1) / math.log(50)
            local jitter = math.random() * 0.2 - 0.1
            return base_delay_ms * util_factor * freq_factor * (1 + jitter)
        end

        function get_user_priority(freq)
            return math.max(1, 10 - math.floor(freq / 5))
        end
    }

    map $request_uri $minute_limit {
        ~*/v[12]/service_bindings     100;
        ~*/v[12]/service_offerings    50;
        ~*/v[12]/service_plans        50;
        ~*/v[12]/service_instances    100;
        default                       200;
    }

    map $request_uri $hour_limit {
        ~*/v[12]/service_bindings     200;
        ~*/v[12]/service_offerings    100;
        ~*/v[12]/service_plans        100;
        ~*/v[12]/service_instances    200;
        default                       400;
    }

    map $uri $api_version {
        ~^/v1/    "v1";
        ~^/v2/    "v2";
        default   "";
    }

    upstream backend_v1 {
        server sm-mock:8899 max_fails=3 fail_timeout=10s;
        keepalive 32;
    }

    upstream backend_v2 {
        server sm-mock-v2:8999 max_fails=3 fail_timeout=10s;
        keepalive 32;
    }

    server {
        listen 80;
        server_name localhost;

        location = /health {
            access_log off;
            add_header Content-Type text/plain;
            return 200 'OK';
        }

        location = /debug {
            add_header Content-Type application/json;
            return 200 '{"backends": {"v1": "sm-mock:8899", "v2": "sm-mock-v2:8999"}}';
        }

        location = /redis-test {
            content_by_lua_block {
                local red = redis:new()
                local redis_host = os.getenv("REDIS_HOST")
                local redis_port = tonumber(os.getenv("REDIS_PORT") or 6379)

                local ok, err = red:connect(redis_host, redis_port)
                if not ok then
                    ngx.status = 500
                    ngx.say("Failed to connect to Redis: ", err)
                    return
                end

                local res, err = red:ping()
                if not res then
                    ngx.say("Failed to ping Redis: ", err)
                    return
                end

                ngx.say("Redis connection successful! PING response: ", res)
                red:close()
            }
        }

        location = /metrics {
            content_by_lua_block {
                local semaphore = ngx.shared.semaphore
                local metrics = {
                    current_utilization = semaphore:get("current_utilization") or 0,
                    semaphore_size = semaphore_size,
                    semaphore_threshold = semaphore_threshold
                }
                ngx.header["Content-Type"] = "application/json"
                ngx.say(require("cjson").encode(metrics))
            }
        }

        location ~ ^/v[12]/.+ {
            access_by_lua_block {
                local semaphore = ngx.shared.semaphore
                local user_requests = ngx.shared.user_requests
                local user_ip = ngx.var.remote_addr

                -- Safe increment with initialization
                local success, err, forcible = semaphore:incr("current_utilization", 1, 0)
                if not success then
                    semaphore:set("current_utilization", 1)
                end
                local current_utilization = semaphore:get("current_utilization") or 0
                ngx.log(ngx.ERR, "Current utilization after increment: ", current_utilization)

                if current_utilization >= (semaphore_size * semaphore_threshold / 100) then
                    local user_freq = user_requests:get(user_ip) or 1
                    local priority = get_user_priority(user_freq)
                    local throttle_time = calculate_throttling_time(current_utilization, user_freq)
                    throttle_time = throttle_time * (1 - priority/10)
                    ngx.sleep(throttle_time / 1000)
                end

                user_requests:incr(user_ip, 1, 60, 1)

                local red = redis:new()
                red:set_timeout(1000)

                local ok, err = red:connect(os.getenv("REDIS_HOST"), tonumber(os.getenv("REDIS_PORT") or 6379))
                if not ok then
                    ngx.log(ngx.ERR, "Failed to connect to Redis: ", err)
                    return ngx.exit(500)
                end

                local time_window = 30
                local minute_key = math.floor(ngx.now() / time_window)
                local hour_key = math.floor(ngx.now() / 120)

                local endpoint = ngx.var.uri:match("/[^/]+/([^/]+)")
                local version = ngx.var.api_version
                local rate_key = version .. ":" .. endpoint

                local minute_limit = tonumber(ngx.var.minute_limit)
                local hour_limit = tonumber(ngx.var.hour_limit)

                local minute_count, err = red:incr(rate_key .. ":30s:" .. minute_key)
                if not minute_count then
                    ngx.log(ngx.ERR, "Failed to increment counter: ", err)
                    return ngx.exit(500)
                end

                red:expire(rate_key .. ":30s:" .. minute_key, time_window)

                if minute_count > minute_limit then
                    ngx.status = 429
                    ngx.header["Content-Type"] = "application/json"
                    ngx.header["Retry-After"] = tostring(time_window - (ngx.now() % time_window))
                    ngx.say(string.format('{"error": "Rate limit exceeded for %s API", "version": "%s", "endpoint": "%s", "window": "30s", "current_count": %d, "limit": %d}',
                        version, version, endpoint, minute_count, minute_limit))
                    red:close()
                    return ngx.exit(ngx.HTTP_TOO_MANY_REQUESTS)
                end

                local hour_count, err = red:incr(rate_key .. ":2m:" .. hour_key)
                if not hour_count then
                    ngx.log(ngx.ERR, "Failed to increment counter: ", err)
                    return ngx.exit(500)
                end

                red:expire(rate_key .. ":2m:" .. hour_key, 120)

                if hour_count > hour_limit then
                    ngx.status = 429
                    ngx.header["Content-Type"] = "application/json"
                    ngx.header["Retry-After"] = tostring(120 - (ngx.now() % 120))
                    ngx.say(string.format('{"error": "Rate limit exceeded for %s API", "version": "%s", "endpoint": "%s", "window": "2m", "current_count": %d, "limit": %d}',
                        version, version, endpoint, hour_count, hour_limit))
                    red:close()
                    return ngx.exit(ngx.HTTP_TOO_MANY_REQUESTS)
                end

                ngx.header["X-API-Version"] = version
                ngx.header["X-RateLimit-30s-Limit"] = minute_limit
                ngx.header["X-RateLimit-30s-Remaining"] = minute_limit - minute_count
                ngx.header["X-RateLimit-30s-Reset"] = time_window - (ngx.now() % time_window)
                ngx.header["X-RateLimit-2m-Limit"] = hour_limit
                ngx.header["X-RateLimit-2m-Remaining"] = hour_limit - hour_count
                ngx.header["X-RateLimit-2m-Reset"] = 120 - (ngx.now() % 120)

                red:set_keepalive(10000, 100)
            }

            log_by_lua_block {
                local semaphore = ngx.shared.semaphore
                local success, err, forcible = semaphore:incr("current_utilization", -1, 0)
                if not success then
                    semaphore:set("current_utilization", 0)
                end
                local current_util = semaphore:get("current_utilization") or 0
                ngx.log(ngx.ERR, "Current utilization after decrement: ", current_util)
            }

            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-API-Version $api_version;

            proxy_connect_timeout 5s;
            proxy_send_timeout 10s;
            proxy_read_timeout 10s;

            set $backend "http://backend_v1";
            if ($api_version = "v2") {
                set $backend "http://backend_v2";
            }

            proxy_pass $backend;

            proxy_next_upstream error timeout http_502;
            proxy_next_upstream_tries 3;

            add_header X-Backend-Server $upstream_addr;
            add_header X-Response-Time $upstream_response_time;
        }
    }
}